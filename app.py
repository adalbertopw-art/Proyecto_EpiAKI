import streamlit as st
import google.generativeai as genai
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import re
import ast # Librer√≠a para el "Plan B" de lectura

# --- CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(page_title="Asistente Epi-AKI", page_icon="ü©∫")

# --- 1. CONEXI√ìN CON GOOGLE SHEETS (BLINDADA) ---
def save_to_google_sheets(data_dict):
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        
        if "google_sheets" in st.secrets:
            # PASO CLAVE: Leer el secreto como texto crudo
            raw_json_str = st.secrets["google_sheets"]["json_key"]
            
            # LIMPIEZA DE CREDENCIALES:
            # A veces al pegar en Secrets, los "\n" se vuelven enters reales que rompen el JSON.
            # Este truco lo arregla permitiendo caracteres de control:
            try:
                creds_dict = json.loads(raw_json_str, strict=False)
            except json.JSONDecodeError:
                # Si falla, intentamos una limpieza manual agresiva de la clave privada
                # Esto es com√∫n si copiaste el JSON desde un PDF o Word
                clean_str = raw_json_str.replace('\n', '\\n') 
                creds_dict = json.loads(clean_str, strict=False)

            creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
            client = gspread.authorize(creds)
            
            # Abre la hoja de c√°lculo
            sheet = client.open("Resultados_EpiAKI").sheet1
            
            # Prepara la fila
            row = [
                data_dict.get("multi_empleo", ""),
                data_dict.get("tipo_centro_principal", ""),
                data_dict.get("modelo_staff", ""),
                data_dict.get("timing_strategy", ""),
                data_dict.get("modalidad_real", ""),
                data_dict.get("dosis_data", ""),
                data_dict.get("anticoagulacion", ""),
                data_dict.get("brecha_recursos", False)
            ]
            sheet.append_row(row)
            return True
        else:
            st.error("‚ùå ERROR: No hay secretos configurados.")
            return False
            
    except Exception as e:
        st.error(f"‚ùå ERROR DE CONEXI√ìN CON EXCEL: {e}")
        return False

# --- 2. CONFIGURACI√ìN DE GEMINI (CEREBRO) ---
if "gemini" in st.secrets:
    genai.configure(api_key=st.secrets["gemini"]["api_key"])
else:
    st.error("Falta la API Key de Gemini en los Secrets.")

# Configuraci√≥n del modelo
generation_config = {
  "temperature": 0.2,
  "top_p": 0.95,
  "top_k": 64,
  "max_output_tokens": 8192,
}

try:
    # Usamos 'gemini-3-flash' que es r√°pido y estable
    model = genai.GenerativeModel(
      model_name="gemini-3-flash-preview",
      generation_config=generation_config,
      system_instruction="""
        **ROL:** Asistente de Investigaci√≥n Senior del estudio 'Epi-AKI Colombia'.
        **TONO:** Colegial, profesional, pero conversacional (de m√©dico a m√©dico).
        
        **OBJETIVO:** Realizar una entrevista fluida. No parezcas un robot interrogador. Usa frases conectoras como "Entiendo la realidad de su centro", "Dato importante", etc.
        
        **REGLAS DE ORO:**
        1. UNA sola pregunta a la vez. Espera la respuesta.
        2. Si la respuesta es muy corta (ej: "si"), asume el contexto y sigue.
        3. AL FINAL: Genera el JSON estrictamente.

        **GUI√ìN DE PREGUNTAS (Adaptativo):**

        **P1 (Contexto Laboral):**
        "Para iniciar y caracterizar la muestra: ¬øEn su pr√°ctica actual ejerce en una √∫nica instituci√≥n o tiene vinculaci√≥n con m√∫ltiples centros (multi-empleo)?"

        **P2 (Centro Principal):**
        "Para las siguientes preguntas, piense solo en su centro de mayor volumen de pacientes. ¬øC√≥mo clasificar√≠a esa instituci√≥n principal: Hospital Universitario, P√∫blico General o Cl√≠nica Privada?"

        **P3 (Modelo de Staff - CR√çTICA):**
        "En ese centro, ¬øqui√©n lidera la prescripci√≥n y programaci√≥n de la m√°quina?
        A) Nefr√≥logo (con apoyo de enfermer√≠a renal)
        B) Modelo Mixto (Decisi√≥n compartida Nefro/UCI)
        C) Liderado por UCI (Intensivista programa)"

        **P4 (Timing):**
        "En un paciente KDIGO 3 s√©ptico pero estable (sin urgencia vital inmediata): ¬øCu√°l es su 'trigger' habitual de inicio?
        A) Estrategia Acelerada (Preventiva)
        B) Estrategia Est√°ndar (Espera vigilante / Indicaci√≥n absoluta)
        C) Guiada por Volumen (Prioriza la sobrecarga h√≠drica)"

        **P5 (Modalidad Real):**
        "En paciente inestable con vasopresores: ¬øQu√© modalidad utiliza **realmente** con mayor frecuencia (considerando disponibilidad de insumos/m√°quinas)?
        A) TRRC (Continua pura)
        B) SLED / PIRR (H√≠brida)
        C) Intermitente"

        **P6 (Dosis - ESPEC√çFICA):**
        "Respecto a la prescripci√≥n:
        - Si usa TRRC: ¬øCu√°l es su dosis efluente objetivo (ml/kg/h)?
        - Si usa SLED: ¬øCu√°ntas horas dura su sesi√≥n est√°ndar?"

        **P7 (Anticoagulaci√≥n):**
        "Finalmente, ¬øcu√°l es su primera l√≠nea de anticoagulaci√≥n del circuito en ese centro?
        A) Citrato Regional
        B) Heparina No Fraccionada
        C) Sin anticoagulaci√≥n"

        **OUTPUT FINAL (JSON):**
        Cuando tengas los 7 datos, desp√≠dete agradeciendo y genera SOLO este JSON:
        {
          "multi_empleo": "Unico" | "Multiple",
          "tipo_centro_principal": "Universitario" | "Publico" | "Privado",
          "modelo_staff": "Solo_Nefro" | "Mixto_UCI" | "Solo_UCI",
          "timing_strategy": "Acelerada" | "Estandar" | "Volumen",
          "modalidad_real": "TRRC" | "SLED" | "HDI",
          "dosis_data": "Texto exacto del usuario",
          "anticoagulacion": "Citrato" | "Heparina" | "Ninguna"
        }
      """
    )
except Exception as e:
    st.error(f"Error configurando Gemini: {e}")

# --- 3. INTERFAZ DE CHAT ---

st.title("ü©∫ Estudio Epi-AKI Colombia")
st.markdown("Comit√© de LRA - ASOCOLNEF")

# Inicializar historial de chat
if "messages" not in st.session_state:
    st.session_state.messages = []
    try:
        st.session_state.chat_session = model.start_chat(history=[])
        # Mensaje de bienvenida CON CONSENTIMIENTO
        welcome_msg = """Bienvenido al Asistente Virtual del Comit√© de LRA (ASOCOLNEF). 
Esta herramienta recolecta datos an√≥nimos sobre patrones de pr√°ctica en Colombia para publicaci√≥n cient√≠fica.

¬øAutoriza el uso de sus respuestas con fines estad√≠sticos? (Responda SI para iniciar)."""
        
        st.session_state.messages.append({"role": "model", "content": welcome_msg})
        st.session_state.chat_session.history.append({"role": "model", "parts": [welcome_msg]})
    except:
        st.warning("Iniciando sistema...")

# Mostrar mensajes anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Capturar input del usuario
if prompt := st.chat_input("Escriba su respuesta aqu√≠..."):
    # Mostrar mensaje usuario
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Enviar a Gemini
    try:
        response = st.session_state.chat_session.send_message(prompt)
        text_response = response.text
        
        # Detectar si hay JSON (Fin de encuesta)
        json_match = re.search(r"\{.*\}", text_response, re.DOTALL)
        
        if json_match:
            # --- ZONA BLINDADA DE LIMPIEZA DE DATOS ---
            try:
                # 1. Capturar el JSON sucio
                json_str = json_match.group(0)
                
                # 2. LIMPIEZA AGRESIVA: Quitamos saltos de l√≠nea invisibles que rompen 'heparina'
                clean_json_str = json_str.replace("\n", " ").replace("\r", "").replace("\t", " ")
                
                # 3. Intentar leer con m√©todo estricto
                data_dict = json.loads(clean_json_str, strict=False)
                
                # 4. Guardar
                if save_to_google_sheets(data_dict):
                    final_msg = "‚úÖ **¬°Datos guardados exitosamente!** Gracias por participar."
                    st.balloons()
                else:
                    final_msg = "‚ö†Ô∏è Datos recibidos, pero hubo un error de conexi√≥n con Excel. (Ver detalle arriba)"

                st.chat_message("model").markdown(final_msg)
                st.session_state.messages.append({"role": "model", "content": final_msg})

            except json.JSONDecodeError:
                # PLAN B: Si falla JSON, usamos AST (Lector de Python m√°s tolerante)
                try:
                    # Convertimos valores de JS a Python
                    python_str = json_str.replace("true", "True").replace("false", "False").replace("null", "None")
                    data_dict = ast.literal_eval(python_str)
                    
                    if save_to_google_sheets(data_dict):
                        final_msg = "‚úÖ **¬°Datos guardados!** (Recuperaci√≥n autom√°tica)."
                        st.balloons()
                        st.chat_message("model").markdown(final_msg)
                        st.session_state.messages.append({"role": "model", "content": final_msg})
                except Exception as e:
                    st.error(f"Error t√©cnico procesando respuesta: {e}")
                    st.code(json_str) # Mostrar c√≥digo para depurar si todo falla
            # ------------------------------------------

        else:
            # Conversaci√≥n normal
            st.chat_message("model").markdown(text_response)
            st.session_state.messages.append({"role": "model", "content": text_response})
            
    except Exception as e:
        st.error(f"Error de conexi√≥n con la IA: {e}")
